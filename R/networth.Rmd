---
title: climbing into the crater
author: Andrew Moore
date: "10/1/2017"
output: 
  html_document:
    code_folding: show
---

Matt Breunig at the [People's Policy Project](http://peoplespolicyproject.org/) published a [post](http://peoplespolicyproject.org/2017/09/27/new-fed-data-black-wealth-cratered-under-obama/) last week looking at 2016 data for family net worth as reported by the [Survey of Consumer Finance (SCF).](https://www.federalreserve.gov/econres/scfindex.htm) The post's title was provacative (*"Black Wealth Cratered Under Obama"*), and the findings that Breunig put up as graphs were equally riling. Using the 2007 and 2016 waves of the survey, Bruenig grouped family net worth into percentiles, and took the difference between each point. Bruenig broke the results down by race/ethnicity, but generally speaking, aside from the wealthiest Americans, most families still haven't recovered to their pre-recession level of household net worth. Bruenig presented the results as line graphs, which didn't strike me as particularly problematic when I read the post, but a friend pointed out that the tweet announcing the post had stacked up a fair amount of salty comments.

<!-- https://twitter.com/VladGutman/status/913292852989325312 -->
<center>![](../salt.png)</center>

A fair amount of the responses seemed to be complaining that line graphs should be restricted to displaying a quantitative variable against an axis representing time. This seems to be an argument based on convention, and I don't really find it persuasive. The quantity we're interested in is the distance between the baseline (0) and the mark indicating the estimate at a given percentile. Bruenig could've easily represented the values as bars (or switched to a [lollipop chart](http://datavizproject.com/data-type/lollipop-chart/)), but in all of these cases, the viewer still needs to look at the axis labels to make sure they're reading the graphic correctly. Elegant visualizations contain enough context and information to ultimately stand on their own, but there's still an active process of consuming them. Pure convention isn't really enough of a justification for me, at least. Bars take up a lot of space/ink on a plot, and feel like a heavy-handed way of expressing the measure's property of *distance from a baseline.*

However, buried in the responses, I think there were a few more substantive questions that could maybe be addressed with some additional data. Criticisms largely centered on the choice of two particular waves in the SCF, 2007 and 2016. Many studious folks in the comments pointed out that Barack Obama wasn't in office at the time of the first wave, and that any observed declines need to account for the financial crisis that would kick into effect between 2008-2009. My read of Bruenig's presentation was that the choice of these two points was meant to provide a sort of pre/post-Obama comparison, as far as the success/failures of his policies over two terms. I don't think this overlooks the recession at all. Granted that the recession occurred during Obama's presidency, it's difficult to think of any domestic economic policies his administration pursued or supported that weren't colored by the crisis. Thus, I think a pre/post comparison (as rough as this is) is worthwhile in evaluating the effectiveness of the administration's response. The extent to which a president can truly affect the course of the economy (or within a certain period of time, such as the length of a presidential term) is a separate issue, but it doesn't seem controversial to say that their impact is significant in some meaningful domains.

Yet, given that the data is available, we don't have to look at a single comparison between 2007 and 2016, if we want to answer the question laid out above. The SCF is conducted every 3 years (typically), so we can add two more lines to Bruenig's graphs to look at 2010 and 2013 as well. Bruenig mentioned on Twitter that the overall patterns came out the same, but I wanted to dig into this on my own as a learning exercise. I've downloaded each of the typical waves of SCF data (Summary Extract Public Data Files from 07-16), and pulled out the relevant variables to recreate Bruenig's plots. I present the code I used to analyze them in R below if you want to follow along, but we're not doing anything super complicated if you want to skip down to the graphs below. 

```{r opts, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r init}
library(tidyverse)
library(scales)
library(reldist)
library(plotly)

# plotting theme
theme_set(
  theme_minimal(base_size = 14) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position  = "bottom",
      legend.title     = element_blank()
    )
)

# pull in the data and prepare the categorical variables for plotting
scf <- read_csv("../data/scf-0716-networth.csv")

scf$year <- factor(scf$year)
scf$race <- factor(scf$race, levels = c("White", "Black", "Hispanic", "Other"))
```

We're interested in the percentile values for each race/ethnicity, across each wave of the survey. Given that we're working with samples (whose composition changes slightly between waves), the percentiles should be adjusted based on the weights provided in the data. The `reldist::wtd.quantile()` function extends R's standard `quantile()` function to allow us to take them into account.

```{r pctiles-1}
# creates a data_frame with a year/race for each row, with the 100 percentiles
# stored as a list column
pctles <- scf %>%
  group_by(year, race) %>%
  do(networth = wtd.quantile(.$networth, seq(.01, 1, .01), weight = .$wgt))

# do() returns the results as a rowwise data_frame, but we want to pull out
# all the observations from the lists and stack them; unnest() gets us there
pctles <- pctles %>%
  group_by(year, race) %>%
  unnest(networth) %>%
  mutate(pctle = 1:length(networth)) %>%
  ungroup
```

Now that we've generated the percentile values for each $group * year$ combination, we can move on to generating the values being displayed in each plot. We're looking at the difference between a given year's percentile values to its corresponding estimate in 2007. Thus, we're not looking at a year-by-year change, but we're comparing each year's position relative to what was recorded in 2007 (just prior to the onset of the Great Recession). The code is accomplishing this somewhat differently, but you could imagine having a spreadsheet with exactly 100 rows, and a column for each year. Each row would contain the value for net worth at a given percentile, and the quantities of interest will be represented as 3 additional columns: column 2007 - column 2010; column 2007 - column 2013; and column 2007 - column 2016.

```{r pctiles-2}
# now we want to take the difference between each wave's values from the 2007
# estimates, making sure we're comparing estimates within race/pctile
pctles <- pctles %>%
  group_by(race, pctle) %>%
  arrange(race, pctle, year) %>%
  mutate(
    diff = abs(networth) - abs(first(networth)),
    diff = ifelse(networth < 0 & first(networth) < 0, -diff, diff),
    diff = ifelse(networth < 0 & first(networth) > 0, -diff, diff)
  ) %>%
  ungroup
```

```{r build-plots, echo = FALSE}
p1 <- pctles %>%
  filter(
    year != 2007,
    pctle < 100,
    race == "White"
  ) %>%
  ggplot(aes(x = pctle, y = diff, color = year)) +
  geom_line() +
  scale_y_continuous(labels = comma) +
  labs(
    x = "Wealth Percentile",
    y = "Change from 2007 (2016 dollars)",
    title = "Change In White Wealth By Percentile"
  )

p2 <- pctles %>%
  filter(
    year != 2007,
    pctle < 100,
    race == "Black"
  ) %>%
  ggplot(aes(x = pctle, y = diff, color = year)) +
  geom_line() +
  scale_y_continuous(labels = comma) +
  labs(
    x = "Wealth Percentile",
    y = "Change from 2007 (2016 dollars)",
    title = "Change In Black Wealth By Percentile"
  )

p3 <- pctles %>%
  filter(
    year != 2007,
    pctle < 100,
    race == "Hispanic"
  ) %>%
  ggplot(aes(x = pctle, y = diff, color = year)) +
  geom_line() +
  scale_y_continuous(labels = comma) +
  labs(
    x = "Wealth Percentile",
    y = "Change from 2007 (2016 dollars)",
    title = "Change In Hispanic/Latino Wealth By Percentile"
  )
```

Next, we can rebuild the plots. Let's start by looking at the change in white wealth. Unlike Bruenig's, these will contain additional lines, allowing us to compare 2010 and 2013 to the 2007 values, in addition to the most recent data from 2016.

```{r p1, echo = FALSE}
ggplotly(p1)
```

 My expectation was that we'd see a fairly strong correlation between the waves, which mostly plays out for the bulk of the distribution. The basic curve/shape of the lines seem consistent, except when you creep up to the 97-99th percentiles. As best I can tell, it seems like recovery for the top 3% didn't really start to pick up until after 2013. This feels sort of surprising to me; my expectation was that the super high percentiles (96-99) would have ridden things out a little better. It looks as if upper-class white families experienced the sharpest downturn closest to the 2007, but we start to see some recovery between the waves in 2013. Lower- and middle-class whites (i.e. percentiles 0-65~) generally dropped about as far as they would by 2010, where they continued to sit until 2016. 

Shifting to black families, we see a slight difference in that the worst declines for families above the median are observed between 2010 and 2013. I'm not exactly sure why there appears to be a delay compared to white families, but it seems significant. It looks as if families above the median only really recover to a little above where they were in 2010. The top-10% in this group appears more like what I expected, in that the 98-99th percentiles seem to fair better than those between 90-97.

```{r p2, echo = FALSE}
ggplotly(p2)
```

Lastly, looking at Hispanic/Latino wealth, we see a similar pattern to the previous group in that the upper-middle class suffers a fairly steep decline, although it looks like 97-99th percentiles weren't really able to avoid the worst effects of the recession, and don't improve until 2016.

```{r p3, echo = FALSE}
ggplotly(p3)
```
